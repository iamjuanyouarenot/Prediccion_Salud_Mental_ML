import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
import joblib
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping

from google.colab import files
uploaded = files.upload()

import io
filename = list(uploaded.keys())[0]
df = pd.read_csv(io.BytesIO(uploaded[filename]))

phq_cols = [f"phq{i}" for i in range(1, 10)]
df["phq9_score"] = df[phq_cols].sum(axis=1)

def clasificar_depresion(score):
    if score <= 4:
        return "Ninguna"
    elif score <= 9:
        return "Leve"
    elif score <= 14:
        return "Moderada"
    elif score <= 19:
        return "Moderadamente severa"
    else:
        return "Severa"

df["Depression_Level"] = df["phq9_score"].apply(clasificar_depresion)

df.dropna(subset=phq_cols, inplace=True)

plt.figure(figsize=(6, 4))
sns.countplot(data=df, x="Depression_Level", order=df["Depression_Level"].value_counts().index)
plt.title("Distribuci贸n de Niveles de Depresi贸n")
plt.xlabel("Nivel")
plt.ylabel("Cantidad")
plt.tight_layout()
plt.show()

X = df[phq_cols]
y = df["Depression_Level"]

le = LabelEncoder()
y_encoded = le.fit_transform(y)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)

model_rf = RandomForestClassifier(n_estimators=100, random_state=42)
model_rf.fit(X_train, y_train)
y_pred_rf = model_rf.predict(X_test)

print("\n--- RANDOM FOREST ---")
print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")
print("\nReporte de Clasificaci贸n:\n", classification_report(y_test, y_pred_rf, target_names=le.classes_))
joblib.dump(model_rf, "modelo_phq9_depresion_rf.pkl")

# Nuevo Modelo: Red Neuronal (MLP con Backpropagation)
model_nn = Sequential()
model_nn.add(Dense(128, input_dim=X.shape[1], activation='relu'))
model_nn.add(Dense(64, activation='relu'))
model_nn.add(Dense(len(le.classes_), activation='softmax'))

model_nn.compile(optimizer='adam',
                 loss='sparse_categorical_crossentropy',
                 metrics=['accuracy'])

early_stop = EarlyStopping(monitor='val_loss', patience=5)

history = model_nn.fit(X_train, y_train, epochs=100, batch_size=16,
                       validation_data=(X_test, y_test), callbacks=[early_stop])

print("\n--- RED NEURONAL (MLP) ---")
loss, accuracy = model_nn.evaluate(X_test, y_test)
print(f"Accuracy (MLP): {accuracy:.4f}")

y_pred_nn = model_nn.predict(X_test).argmax(axis=1)
print("\nReporte de Clasificaci贸n MLP:\n", classification_report(y_test, y_pred_nn, target_names=le.classes_))

model_nn.save('modelo_phq9_depresion_nn.h5')
